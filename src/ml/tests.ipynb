{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import mlflow\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from src.ml.data.splitting import create_data_splits\n",
    "from src.ml.modeling import (\n",
    "    model_factory,\n",
    "    optimizer_factory,\n",
    ")\n",
    "from src.ml.utils.set_seed import set_seed\n",
    "\n",
    "from datetime import datetime\n",
    "from loguru import logger\n",
    "from pathlib import Path\n",
    "from shutil import copy, copytree, rmtree\n",
    "\n",
    "import yaml\n",
    "\n",
    "from src.ml.train_neural_network import train_neural_network\n",
    "from src.ml.data import data_sets_factory\n",
    "from src.ml.preprocessing import preprocessing_factory\n",
    "from src.ml.utils.set_seed import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = Path(\"src/ml/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 00:46:52.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mLoading config file.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load config file\n",
    "\n",
    "logger.info(\"Loading config file.\")\n",
    "\n",
    "with open(CONFIG_FILE, \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 00:46:52.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mLoading data.\u001b[0m\n",
      "\u001b[32m2024-12-13 00:46:52.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mLoaded 1 data sets.\u001b[0m\n",
      "\u001b[32m2024-12-13 00:46:52.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mStart preprocessing.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "logger.info(\"Loading data.\")\n",
    "\n",
    "data_sets = data_sets_factory(**config[\"data_set\"])\n",
    "logger.info(\"Loaded {} data sets.\", len(data_sets))\n",
    "\n",
    "# preprocess data\n",
    "\n",
    "logger.info(\"Start preprocessing.\")\n",
    "\n",
    "for preprocessing_step in config[\"preprocessing\"]:\n",
    "    logger.info(\"Perform {} preprocessing.\", preprocessing_step[\"name\"])\n",
    "\n",
    "    transform = preprocessing_factory(**preprocessing_step)\n",
    "    data_sets = [transform(data_set) for data_set in data_sets]\n",
    "\n",
    "dataset = data_sets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = create_data_splits(\n",
    "    dataset, **config[\"training\"][\"splitting_config\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, **config[\"training\"][\"dataloader_config\"])\n",
    "test_loader = DataLoader(test_dataset,batch_size=10)\n",
    "val_loader = DataLoader(val_dataset)\n",
    "\n",
    "optimizer = optimizer_factory(**config[\"training\"][\"optimizer_config\"])\n",
    "model = model_factory(\n",
    "    optimizer=optimizer,\n",
    "    dim=len(train_dataset[0][\"branch_lengths\"]),\n",
    "    context_dim=len(train_dataset[0][\"clades_one_hot\"]),\n",
    "    **config[\"training\"][\"model_config\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml.modeling.conditional_tree_flow import ConditionalTreeFlow\n",
    "\n",
    "model = ConditionalTreeFlow.load_from_checkpoint(\"ml_data/models/debug_simple_conditional_flow/epoch=19-val_loss=2300.96.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'branch_lengths': tensor([[0.0519, 0.0486, 0.0490, 0.0489, 0.0498, 0.0497, 0.0502, 0.0517, 0.0495,\n",
       "           0.0491],\n",
       "          [0.0517, 0.0503, 0.0498, 0.0511, 0.0515, 0.0513, 0.0513, 0.0510, 0.0496,\n",
       "           0.0488],\n",
       "          [0.0492, 0.0503, 0.0492, 0.0509, 0.0517, 0.0494, 0.0508, 0.0507, 0.0504,\n",
       "           0.0502],\n",
       "          [0.0499, 0.0503, 0.0495, 0.0500, 0.0488, 0.0502, 0.0478, 0.0486, 0.0511,\n",
       "           0.0499],\n",
       "          [0.0492, 0.0489, 0.0484, 0.0508, 0.0504, 0.0518, 0.0516, 0.0516, 0.0517,\n",
       "           0.0489],\n",
       "          [0.0508, 0.0507, 0.0511, 0.0509, 0.0494, 0.0507, 0.0505, 0.0508, 0.0517,\n",
       "           0.0492],\n",
       "          [0.0493, 0.0510, 0.0499, 0.0492, 0.0498, 0.0492, 0.0497, 0.0493, 0.0499,\n",
       "           0.0506],\n",
       "          [0.0485, 0.0502, 0.0488, 0.0515, 0.0489, 0.0491, 0.0478, 0.0508, 0.0495,\n",
       "           0.0485],\n",
       "          [0.0510, 0.0502, 0.0507, 0.0511, 0.0515, 0.0502, 0.0494, 0.0499, 0.0500,\n",
       "           0.0484],\n",
       "          [0.0515, 0.0481, 0.0488, 0.0511, 0.0500, 0.0504, 0.0488, 0.0507, 0.0505,\n",
       "           0.0503]]),\n",
       "  'clades_one_hot': tensor([[0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
       "           1., 1.],\n",
       "          [1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1.],\n",
       "          [1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "           1., 1.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "           0., 0.],\n",
       "          [0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "           1., 0.],\n",
       "          [0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "           0., 1.],\n",
       "          [0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "           0., 1.],\n",
       "          [1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0.],\n",
       "          [0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "           0., 0.],\n",
       "          [1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 1.]])},\n",
       " {'branch_lengths': tensor([[0.0519, 0.0486, 0.0490, 0.0489, 0.0498, 0.0497, 0.0502, 0.0517, 0.0495,\n",
       "           0.0491],\n",
       "          [0.0517, 0.0503, 0.0498, 0.0511, 0.0515, 0.0513, 0.0513, 0.0510, 0.0496,\n",
       "           0.0488],\n",
       "          [0.0492, 0.0503, 0.0492, 0.0509, 0.0517, 0.0494, 0.0508, 0.0507, 0.0504,\n",
       "           0.0502],\n",
       "          [0.0499, 0.0503, 0.0495, 0.0500, 0.0488, 0.0502, 0.0478, 0.0486, 0.0511,\n",
       "           0.0499],\n",
       "          [0.0492, 0.0489, 0.0484, 0.0508, 0.0504, 0.0518, 0.0516, 0.0516, 0.0517,\n",
       "           0.0489],\n",
       "          [0.0508, 0.0507, 0.0511, 0.0509, 0.0494, 0.0507, 0.0505, 0.0508, 0.0517,\n",
       "           0.0492],\n",
       "          [0.0493, 0.0510, 0.0499, 0.0492, 0.0498, 0.0492, 0.0497, 0.0493, 0.0499,\n",
       "           0.0506],\n",
       "          [0.0485, 0.0502, 0.0488, 0.0515, 0.0489, 0.0491, 0.0478, 0.0508, 0.0495,\n",
       "           0.0485],\n",
       "          [0.0510, 0.0502, 0.0507, 0.0511, 0.0515, 0.0502, 0.0494, 0.0499, 0.0500,\n",
       "           0.0484],\n",
       "          [0.0515, 0.0481, 0.0488, 0.0511, 0.0500, 0.0504, 0.0488, 0.0507, 0.0505,\n",
       "           0.0503]], grad_fn=<SubBackward0>),\n",
       "  'clades_one_hot': tensor([[0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
       "           1., 1.],\n",
       "          [1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1.],\n",
       "          [1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "           1., 1.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "           0., 0.],\n",
       "          [0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "           1., 0.],\n",
       "          [0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "           0., 1.],\n",
       "          [0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "           0., 1.],\n",
       "          [1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0.],\n",
       "          [0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "           0., 0.],\n",
       "          [1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 1.]]),\n",
       "  'log_dj': tensor([-48.6419, -48.6419, -48.6419, -48.6419, -48.6419, -48.6419, -48.6419,\n",
       "          -48.6419, -48.6419, -48.6419], grad_fn=<AddBackward0>)})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(test_loader))\n",
    "latent = model.forward(sample)\n",
    "output = model.inverse(latent)\n",
    "sample, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'branch_lengths': tensor([[0.0509, 0.0490, 0.0498, 0.0499, 0.0494, 0.0505, 0.0491, 0.0493, 0.0522,\n",
       "          0.0506],\n",
       "         [0.0493, 0.0504, 0.0490, 0.0503, 0.0511, 0.0516, 0.0518, 0.0486, 0.0521,\n",
       "          0.0492],\n",
       "         [0.0484, 0.0479, 0.0492, 0.0507, 0.0497, 0.0505, 0.0489, 0.0499, 0.0500,\n",
       "          0.0496],\n",
       "         [0.0515, 0.0506, 0.0509, 0.0495, 0.0500, 0.0498, 0.0515, 0.0487, 0.0525,\n",
       "          0.0530],\n",
       "         [0.0511, 0.0496, 0.0491, 0.0508, 0.0510, 0.0492, 0.0493, 0.0511, 0.0494,\n",
       "          0.0488],\n",
       "         [0.0489, 0.0492, 0.0522, 0.0500, 0.0503, 0.0501, 0.0506, 0.0501, 0.0502,\n",
       "          0.0494],\n",
       "         [0.0492, 0.0498, 0.0490, 0.0488, 0.0495, 0.0508, 0.0489, 0.0509, 0.0516,\n",
       "          0.0518],\n",
       "         [0.0485, 0.0477, 0.0506, 0.0502, 0.0498, 0.0506, 0.0518, 0.0487, 0.0510,\n",
       "          0.0514],\n",
       "         [0.0516, 0.0505, 0.0506, 0.0487, 0.0501, 0.0496, 0.0493, 0.0506, 0.0484,\n",
       "          0.0504],\n",
       "         [0.0489, 0.0524, 0.0512, 0.0492, 0.0497, 0.0490, 0.0498, 0.0494, 0.0496,\n",
       "          0.0493]]),\n",
       " 'clades_one_hot': tensor([[1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "          0., 0.],\n",
       "         [0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
       "          0., 1.],\n",
       "         [1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
       "          0., 1.],\n",
       "         [1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "          0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "          1., 1.],\n",
       "         [0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "          0., 0.]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(test_loader))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z': tensor([[-1.3902e-01, -2.6560e-03, -7.9882e-03,  4.9895e-02, -1.1855e-03,\n",
       "          -4.6577e-02,  1.8443e-01,  5.9022e-03,  5.2162e-02, -1.0939e-01],\n",
       "         [-1.6355e-01,  1.4747e-03, -1.1370e-02,  5.0322e-02,  1.1467e-02,\n",
       "          -6.1454e-02,  2.2058e-01,  2.7310e-02,  5.2133e-02, -1.2408e-01],\n",
       "         [-1.3487e-01, -3.3168e-02, -5.0880e-03,  5.0673e-02,  3.1648e-03,\n",
       "          -4.2069e-02,  2.3836e-01,  2.1490e-02,  5.0024e-02, -1.3239e-01],\n",
       "         [-1.2149e-01, -8.6101e-03, -4.7958e-03,  4.9473e-02, -4.1558e-03,\n",
       "          -5.1250e-02,  1.5665e-01,  1.7641e-02,  5.2458e-02, -1.0876e-01],\n",
       "         [-1.4606e-01, -1.7655e-02, -6.2293e-03,  5.0765e-02,  2.0278e-03,\n",
       "          -8.5442e-02,  1.7926e-01,  2.9374e-02,  4.9440e-02, -1.2760e-01],\n",
       "         [-1.5798e-01, -3.2042e-03, -8.6136e-03,  5.0026e-02, -2.9738e-03,\n",
       "          -4.6176e-02,  2.0000e-01,  1.0446e-02,  5.0161e-02, -1.2808e-01],\n",
       "         [-1.7710e-01, -1.5226e-02, -9.3870e-03,  4.8841e-02,  4.7702e-03,\n",
       "          -5.6173e-02,  1.8029e-01,  1.2105e-02,  5.1552e-02, -1.7806e-01],\n",
       "         [-1.0029e-01, -3.3730e-03, -7.3886e-03,  5.0203e-02, -7.7339e-03,\n",
       "          -4.7631e-02,  1.6593e-01,  2.4476e-03,  5.1003e-02, -1.0930e-01],\n",
       "         [-1.5294e-01, -1.1485e-02, -5.5187e-03,  4.8697e-02,  4.8516e-05,\n",
       "          -4.4898e-02,  1.8213e-01,  9.2996e-03,  4.8444e-02, -1.6131e-01],\n",
       "         [-1.7572e-01,  8.4423e-04, -2.7700e-02,  4.9161e-02,  8.7055e-03,\n",
       "          -6.2032e-02,  2.2914e-01,  3.6597e-02,  4.9643e-02, -1.7212e-01]],\n",
       "        grad_fn=<MulBackward0>),\n",
       " 'context': tensor([[1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "          0., 0.],\n",
       "         [0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
       "          0., 1.],\n",
       "         [1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
       "          0., 1.],\n",
       "         [1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "          0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "          1., 1.],\n",
       "         [0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "          0., 0.]]),\n",
       " 'log_dj': tensor([-52.4546, -52.4546, -52.4546, -52.4546, -52.4546, -52.4546, -52.4546,\n",
       "         -52.4546, -52.4546, -52.4546], grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent = model.forward(sample)\n",
    "latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2818, -0.4083,  1.3057,  1.3644,  0.0135, -0.8820,  0.3757, -0.0398,\n",
       "          1.8833,  0.0425]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 1 but got size 10 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m latent[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m output\n",
      "File \u001b[0;32m~/Documents/Thesis/Validation/src/ml/modeling/normalizing_flow.py:46\u001b[0m, in \u001b[0;36mNormalizingFlow.inverse\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     43\u001b[0m transformed \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m flow \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflows[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m---> 46\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtransformed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     transformed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(transformed)\n",
      "File \u001b[0;32m~/Documents/Thesis/Validation/src/ml/modeling/layers/affine_coupling_flow_layer.py:49\u001b[0m, in \u001b[0;36mMaskedAffineFlowLayer.inverse\u001b[0;34m(self, z, context, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m z_masked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m*\u001b[39m z\n\u001b[1;32m     47\u001b[0m embedded_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_embedding(context)\n\u001b[0;32m---> 49\u001b[0m scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_masked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedded_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m translation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslate(z_masked, embedded_context)\n\u001b[1;32m     52\u001b[0m scale \u001b[38;5;241m=\u001b[39m scale \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask)\n",
      "File \u001b[0;32m~/Documents/Thesis/Validation/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Thesis/Validation/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Thesis/Validation/src/ml/modeling/conditional_tree_flow.py:28\u001b[0m, in \u001b[0;36mScalingModule.forward\u001b[0;34m(self, z, y)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, z, y):\n\u001b[0;32m---> 28\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_1(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     29\u001b[0m     z \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(z)\n\u001b[1;32m     30\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_2(z)\n",
      "File \u001b[0;32m~/Documents/Thesis/Validation/.venv/lib/python3.11/site-packages/torch/utils/_device.py:106\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 1 but got size 10 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "latent[\"z\"] = torch.randn(1, 10)\n",
    "output = model.inverse(latent)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
