{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import mlflow\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from src.ml.data.splitting import create_data_splits\n",
    "from src.ml.modeling import (\n",
    "    model_factory,\n",
    "    optimizer_factory,\n",
    ")\n",
    "from src.ml.utils.set_seed import set_seed\n",
    "\n",
    "from datetime import datetime\n",
    "from loguru import logger\n",
    "from pathlib import Path\n",
    "from shutil import copy, copytree, rmtree\n",
    "\n",
    "import yaml\n",
    "\n",
    "from src.ml.train_neural_network import train_neural_network\n",
    "from src.ml.data import data_sets_factory\n",
    "from src.ml.preprocessing import preprocessing_factory\n",
    "from src.ml.utils.set_seed import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = Path(\"src/ml/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 01:07:38.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mLoading config file.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load config file\n",
    "\n",
    "logger.info(\"Loading config file.\")\n",
    "\n",
    "with open(CONFIG_FILE, \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 01:07:38.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mLoading data.\u001b[0m\n",
      "\u001b[32m2024-12-13 01:07:38.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mLoaded 1 data sets.\u001b[0m\n",
      "\u001b[32m2024-12-13 01:07:38.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mStart preprocessing.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "logger.info(\"Loading data.\")\n",
    "\n",
    "data_sets = data_sets_factory(**config[\"data_set\"])\n",
    "logger.info(\"Loaded {} data sets.\", len(data_sets))\n",
    "\n",
    "# preprocess data\n",
    "\n",
    "logger.info(\"Start preprocessing.\")\n",
    "\n",
    "for preprocessing_step in config[\"preprocessing\"]:\n",
    "    logger.info(\"Perform {} preprocessing.\", preprocessing_step[\"name\"])\n",
    "\n",
    "    transform = preprocessing_factory(**preprocessing_step)\n",
    "    data_sets = [transform(data_set) for data_set in data_sets]\n",
    "\n",
    "dataset = data_sets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = create_data_splits(\n",
    "    dataset, **config[\"training\"][\"splitting_config\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, **config[\"training\"][\"dataloader_config\"])\n",
    "test_loader = DataLoader(test_dataset,batch_size=1)\n",
    "val_loader = DataLoader(val_dataset)\n",
    "\n",
    "optimizer = optimizer_factory(**config[\"training\"][\"optimizer_config\"])\n",
    "model = model_factory(\n",
    "    optimizer=optimizer,\n",
    "    dim=len(train_dataset[0][\"branch_lengths\"]),\n",
    "    **config[\"training\"][\"model_config\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml.modeling.conditional_tree_flow import ConditionalTreeFlow\n",
    "\n",
    "model = ConditionalTreeFlow.load_from_checkpoint(\"ml_data/models/debug_simple_conditional_flow/epoch=19-val_loss=507080.16.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'branch_lengths': tensor([[ 9.8746e-04,  2.8777e-05, -1.5181e-04,  1.8398e-03,  1.2263e-03,\n",
       "           -1.7070e-03,  3.0562e-04,  1.3443e-05, -2.9067e-04,  6.3688e-04]]),\n",
       "  'clades_one_hot': tensor([[0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
       "           0., 1.]])},\n",
       " {'branch_lengths': tensor([[ 9.8746e-04,  2.8777e-05, -1.5181e-04,  1.8398e-03,  1.2263e-03,\n",
       "           -1.7070e-03,  3.0562e-04,  1.3443e-05, -2.9067e-04,  6.3689e-04]],\n",
       "         grad_fn=<SubBackward0>),\n",
       "  'log_dj': tensor([0.5187], grad_fn=<AddBackward0>)})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(test_loader))\n",
    "latent = model.forward(sample)\n",
    "output = model.inverse(latent)\n",
    "sample, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'branch_lengths': tensor([[-0.0008, -0.0003, -0.0007, -0.0001,  0.0016, -0.0006,  0.0007,  0.0010,\n",
       "           0.0011,  0.0009]]),\n",
       " 'clades_one_hot': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
       "          0., 0.]])}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(test_loader))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z': tensor([[-0.0008, -0.0003, -0.0007,  0.2210,  0.0016, -0.0006,  0.0163,  0.0010,\n",
       "           0.0011, -0.1399]], grad_fn=<MulBackward0>),\n",
       " 'log_dj': tensor([0.5175], grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent = model.forward(sample)\n",
    "latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'branch_lengths': tensor([-1.2467,  0.8291,  0.2576, -1.9265, -0.9135,  1.1018, -0.0609, -0.3466,\n",
       "          2.3803,  0.4958], grad_fn=<SubBackward0>),\n",
       " 'log_dj': tensor([0.5175], grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent[\"z\"] = torch.distributions.normal.Normal(loc=0.0, scale=1.0).sample((10,))\n",
    "output = model.inverse(latent)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
