{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import mlflow\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from src.ml.data.splitting import create_data_splits\n",
    "from src.ml.modeling import (\n",
    "    model_factory,\n",
    "    optimizer_factory,\n",
    ")\n",
    "from src.ml.utils.set_seed import set_seed\n",
    "\n",
    "from datetime import datetime\n",
    "from loguru import logger\n",
    "from pathlib import Path\n",
    "from shutil import copy, copytree, rmtree\n",
    "\n",
    "import yaml\n",
    "\n",
    "from src.ml.train_neural_network import train_neural_network\n",
    "from src.ml.data import data_sets_factory\n",
    "from src.ml.preprocessing import preprocessing_factory\n",
    "from src.ml.utils.set_seed import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = Path(\"src/ml/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 02:53:42.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mLoading config file.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load config file\n",
    "\n",
    "logger.info(\"Loading config file.\")\n",
    "\n",
    "with open(CONFIG_FILE, \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 02:53:42.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mLoading data.\u001b[0m\n",
      "\u001b[32m2024-12-13 02:53:42.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mLoaded 1 data sets.\u001b[0m\n",
      "\u001b[32m2024-12-13 02:53:42.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mStart preprocessing.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "logger.info(\"Loading data.\")\n",
    "\n",
    "data_sets = data_sets_factory(**config[\"data_set\"])\n",
    "logger.info(\"Loaded {} data sets.\", len(data_sets))\n",
    "\n",
    "# preprocess data\n",
    "\n",
    "logger.info(\"Start preprocessing.\")\n",
    "\n",
    "for preprocessing_step in config[\"preprocessing\"]:\n",
    "    logger.info(\"Perform {} preprocessing.\", preprocessing_step[\"name\"])\n",
    "\n",
    "    transform = preprocessing_factory(**preprocessing_step)\n",
    "    data_sets = [transform(data_set) for data_set in data_sets]\n",
    "\n",
    "dataset = data_sets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = create_data_splits(\n",
    "    dataset, **config[\"training\"][\"splitting_config\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, **config[\"training\"][\"dataloader_config\"])\n",
    "test_loader = DataLoader(test_dataset,batch_size=1)\n",
    "val_loader = DataLoader(val_dataset)\n",
    "\n",
    "optimizer = optimizer_factory(**config[\"training\"][\"optimizer_config\"])\n",
    "model = model_factory(\n",
    "    optimizer=optimizer,\n",
    "    dim=len(train_dataset[0][\"branch_lengths\"]),\n",
    "    **config[\"training\"][\"model_config\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml.modeling.conditional_tree_flow import ConditionalTreeFlow\n",
    "\n",
    "model = ConditionalTreeFlow.load_from_checkpoint(\"ml_data/models/debug_simple_conditional_flow/epoch=98-val_loss=-10161.30.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'branch_lengths': tensor([[-1.8104e-03, -6.8320e-04,  4.2604e-05, -5.3133e-04,  3.2836e-05,\n",
       "           2.1246e-04, -1.0737e-03, -2.1067e-04, -6.0958e-04,  1.3781e-03]]),\n",
       " 'clades_one_hot': tensor([[1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "          1., 0.]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(test_loader))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z': tensor([[-1.0879,  0.0057, -0.5851, -0.6469, -0.4700,  1.0595, -1.3038,  0.5304,\n",
       "           1.4702,  1.1122]], grad_fn=<MulBackward0>),\n",
       " 'context': tensor([[1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "          1., 0.]]),\n",
       " 'log_dj': tensor([53.9412], grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent = model.forward(sample)\n",
    "latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'branch_lengths': tensor([[-1.8105e-03, -6.8316e-04,  4.2498e-05, -5.3146e-04,  3.2805e-05,\n",
       "           2.1242e-04, -1.0737e-03, -2.1067e-04, -6.0964e-04,  1.3781e-03]],\n",
       "        grad_fn=<SubBackward0>),\n",
       " 'clades_one_hot': tensor([[1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "          1., 0.]]),\n",
       " 'log_dj': tensor([53.9412], grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.inverse(latent)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'branch_lengths': tensor([-0.0018, -0.1930,  0.5294, -0.5510,  0.0073, -0.2338, -0.0323,  0.0152,\n",
       "          0.0274, -0.0170], grad_fn=<SubBackward0>),\n",
       " 'clades_one_hot': tensor([[1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "          1., 0.]]),\n",
       " 'log_dj': tensor([53.9412], grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior = model.prior.sample((10,))\n",
    "latent[\"z\"] = prior.clone()\n",
    "output = model.inverse(latent)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
