{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import mlflow\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from src.ml.data.splitting import create_data_splits\n",
    "from src.ml.modeling import (\n",
    "    model_factory,\n",
    "    optimizer_factory,\n",
    ")\n",
    "from src.ml.utils.set_seed import set_seed\n",
    "\n",
    "from datetime import datetime\n",
    "from loguru import logger\n",
    "from pathlib import Path\n",
    "from shutil import copy, copytree, rmtree\n",
    "\n",
    "import yaml\n",
    "\n",
    "from src.ml.train_neural_network import train_neural_network\n",
    "from src.ml.data import data_sets_factory\n",
    "from src.ml.preprocessing import preprocessing_factory\n",
    "from src.ml.utils.set_seed import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = Path(\"src/ml/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 02:21:58.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mLoading config file.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load config file\n",
    "\n",
    "logger.info(\"Loading config file.\")\n",
    "\n",
    "with open(CONFIG_FILE, \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 02:21:58.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mLoading data.\u001b[0m\n",
      "\u001b[32m2024-12-13 02:21:58.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mLoaded 1 data sets.\u001b[0m\n",
      "\u001b[32m2024-12-13 02:21:58.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mStart preprocessing.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "logger.info(\"Loading data.\")\n",
    "\n",
    "data_sets = data_sets_factory(**config[\"data_set\"])\n",
    "logger.info(\"Loaded {} data sets.\", len(data_sets))\n",
    "\n",
    "# preprocess data\n",
    "\n",
    "logger.info(\"Start preprocessing.\")\n",
    "\n",
    "for preprocessing_step in config[\"preprocessing\"]:\n",
    "    logger.info(\"Perform {} preprocessing.\", preprocessing_step[\"name\"])\n",
    "\n",
    "    transform = preprocessing_factory(**preprocessing_step)\n",
    "    data_sets = [transform(data_set) for data_set in data_sets]\n",
    "\n",
    "dataset = data_sets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = create_data_splits(\n",
    "    dataset, **config[\"training\"][\"splitting_config\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, **config[\"training\"][\"dataloader_config\"])\n",
    "test_loader = DataLoader(test_dataset,batch_size=1)\n",
    "val_loader = DataLoader(val_dataset)\n",
    "\n",
    "optimizer = optimizer_factory(**config[\"training\"][\"optimizer_config\"])\n",
    "model = model_factory(\n",
    "    optimizer=optimizer,\n",
    "    dim=len(train_dataset[0][\"branch_lengths\"]),\n",
    "    **config[\"training\"][\"model_config\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml.modeling.conditional_tree_flow import ConditionalTreeFlow\n",
    "\n",
    "model = ConditionalTreeFlow.load_from_checkpoint(\"ml_data/models/debug_simple_conditional_flow/epoch=46-val_loss=-3978.27-v1.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'branch_lengths': tensor([[-8.5946e-05, -1.0166e-04, -2.9394e-04,  1.0320e-03, -1.3393e-03,\n",
       "          -9.7662e-04,  9.8861e-04,  5.5989e-04, -1.6961e-03, -3.0541e-04]]),\n",
       " 'clades_one_hot': tensor([[1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "          0., 1.]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(test_loader))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z': tensor([[-0.6564, -1.1955, -1.4612,  0.0499,  1.4594, -0.3294,  1.3576, -1.6930,\n",
       "          -0.3948,  1.4051]], grad_fn=<MulBackward0>),\n",
       " 'context': tensor([[1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "          0., 1.]]),\n",
       " 'log_dj': tensor([31.9492], grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent = model.forward(sample)\n",
    "latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'branch_lengths': tensor([-7.3658,  0.8086,  2.1286,  2.2383, -1.8624, -0.7282, -3.7896, -0.3223,\n",
       "         -0.7825, -1.1896], grad_fn=<SubBackward0>),\n",
       " 'clades_one_hot': tensor([[1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "          0., 1.]]),\n",
       " 'log_dj': tensor([31.9492], grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent[\"z\"] = torch.distributions.normal.Normal(loc=0.0, scale=1.0).sample((10,))\n",
    "output = model.inverse(latent)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
