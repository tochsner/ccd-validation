{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import mlflow\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from src.ml.data.splitting import create_data_splits\n",
    "from src.ml.modeling import (\n",
    "    model_factory,\n",
    "    optimizer_factory,\n",
    ")\n",
    "from src.ml.utils.set_seed import set_seed\n",
    "\n",
    "from datetime import datetime\n",
    "from loguru import logger\n",
    "from pathlib import Path\n",
    "from shutil import copy, copytree, rmtree\n",
    "\n",
    "import yaml\n",
    "\n",
    "from src.ml.train_neural_network import train_neural_network\n",
    "from src.ml.data import data_sets_factory\n",
    "from src.ml.preprocessing import preprocessing_factory\n",
    "from src.ml.utils.set_seed import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = Path(\"src/ml/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 11:06:27.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mLoading config file.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load config file\n",
    "\n",
    "logger.info(\"Loading config file.\")\n",
    "\n",
    "with open(CONFIG_FILE, \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 11:06:28.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mLoading data.\u001b[0m\n",
      "\u001b[32m2024-12-13 11:06:38.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mLoaded 1 data sets.\u001b[0m\n",
      "\u001b[32m2024-12-13 11:06:38.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mStart preprocessing.\u001b[0m\n",
      "\u001b[32m2024-12-13 11:06:38.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mPerform add_taxa_names preprocessing.\u001b[0m\n",
      "\u001b[32m2024-12-13 11:06:39.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mPerform add_clade_information preprocessing.\u001b[0m\n",
      "\u001b[32m2024-12-13 11:06:42.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mPerform remove_tree preprocessing.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "logger.info(\"Loading data.\")\n",
    "\n",
    "data_sets = data_sets_factory(**config[\"data_set\"])\n",
    "logger.info(\"Loaded {} data sets.\", len(data_sets))\n",
    "\n",
    "# preprocess data\n",
    "\n",
    "logger.info(\"Start preprocessing.\")\n",
    "\n",
    "for preprocessing_step in config[\"preprocessing\"]:\n",
    "    logger.info(\"Perform {} preprocessing.\", preprocessing_step[\"name\"])\n",
    "\n",
    "    transform = preprocessing_factory(**preprocessing_step)\n",
    "    data_sets = [transform(data_set) for data_set in data_sets]\n",
    "\n",
    "dataset = data_sets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = create_data_splits(\n",
    "    dataset, **config[\"training\"][\"splitting_config\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, **config[\"training\"][\"dataloader_config\"])\n",
    "test_loader = DataLoader(test_dataset,batch_size=1)\n",
    "val_loader = DataLoader(val_dataset)\n",
    "\n",
    "optimizer = optimizer_factory(**config[\"training\"][\"optimizer_config\"])\n",
    "model = model_factory(\n",
    "    optimizer=optimizer,\n",
    "    dim=len(train_dataset[0][\"branch_lengths\"]),\n",
    "    **config[\"training\"][\"model_config\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml.modeling.conditional_tree_flow import ConditionalTreeFlow\n",
    "\n",
    "model = ConditionalTreeFlow.load_from_checkpoint(\"ml_data/models/debug_yule_10/epoch=49-val_loss=2628.66.ckpt\")\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trees_file': ['data/mcmc_runs/yule-10_140.trees'],\n",
       " 'tree_index': tensor([34217]),\n",
       " 'taxa_names': [('0',),\n",
       "  ('8',),\n",
       "  ('6',),\n",
       "  ('5',),\n",
       "  ('7',),\n",
       "  ('3',),\n",
       "  ('4',),\n",
       "  ('9',),\n",
       "  ('1',),\n",
       "  ('2',)],\n",
       " 'clades': [tensor([3]),\n",
       "  tensor([12]),\n",
       "  tensor([19]),\n",
       "  tensor([31]),\n",
       "  tensor([96]),\n",
       "  tensor([224]),\n",
       "  tensor([255]),\n",
       "  tensor([768]),\n",
       "  tensor([1023])],\n",
       " 'branch_lengths': tensor([[0.0105, 0.0028, 0.0049, 0.0012, 0.0004, 0.0042, 0.0075, 0.0053, 0.0362]]),\n",
       " 'clades_one_hot': tensor([[1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 1.]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(test_loader))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z': tensor([[ 0.5680,  0.2705, -0.0076, -0.8350, -0.8668,  0.4092,  0.1815,  0.2427,\n",
       "          -0.1909]], grad_fn=<MulBackward0>),\n",
       " 'context': tensor([[1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 1.]]),\n",
       " 'log_dj': tensor([51.6559], grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent = model.forward(sample)\n",
    "latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'branch_lengths': tensor([[0.0105, 0.0028, 0.0049, 0.0012, 0.0004, 0.0042, 0.0075, 0.0053, 0.0362]],\n",
       "         grad_fn=<ExpBackward0>),\n",
       "  'clades_one_hot': tensor([[1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1.]]),\n",
       "  'log_dj': tensor([51.6559], grad_fn=<AddBackward0>)},\n",
       " {'trees_file': ['data/mcmc_runs/yule-10_140.trees'],\n",
       "  'tree_index': tensor([34217]),\n",
       "  'taxa_names': [('0',),\n",
       "   ('8',),\n",
       "   ('6',),\n",
       "   ('5',),\n",
       "   ('7',),\n",
       "   ('3',),\n",
       "   ('4',),\n",
       "   ('9',),\n",
       "   ('1',),\n",
       "   ('2',)],\n",
       "  'clades': [tensor([3]),\n",
       "   tensor([12]),\n",
       "   tensor([19]),\n",
       "   tensor([31]),\n",
       "   tensor([96]),\n",
       "   tensor([224]),\n",
       "   tensor([255]),\n",
       "   tensor([768]),\n",
       "   tensor([1023])],\n",
       "  'branch_lengths': tensor([[0.0105, 0.0028, 0.0049, 0.0012, 0.0004, 0.0042, 0.0075, 0.0053, 0.0362]]),\n",
       "  'clades_one_hot': tensor([[1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1.]])})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.inverse(latent)\n",
    "output, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'branch_lengths': tensor([0.0107, 0.0007, 0.0020, 0.0016, 0.0017, 0.0011, 0.0045, 0.0052, 0.0260],\n",
       "        grad_fn=<ExpBackward0>),\n",
       " 'clades_one_hot': tensor([[1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 1.]]),\n",
       " 'log_dj': tensor([51.6559], grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior = model.prior.sample((9,))\n",
    "latent[\"z\"] = prior.clone()\n",
    "output = model.inverse(latent)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
